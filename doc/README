
*******************
**** IMPORTANT ****
*******************

This is a descrioption of all of the scripts you need to run to build the SQLite database.
For a description of how to get data for input into these scripts see INSTALL.
For a description of analysis scripts to run after running these setup scripts,
    see help_texts.

-------------------------------
-------------------------------

DESCRIPTION OF PIPELINE - PART 1 ("main.sh")

To run:

./main.sh

(must be run from the root directory of the repository)

This first part of the pipeline begins with the input files (see INSTALL) and ends with
some processed gene tables with easier access to gene lengths and organisms, and
all of the BLAST results and gene neighborhoods pre-computed for easy access.

The shell script "main.sh" pipes each of the raw data
into the functions that are necessary and outputs the results of these functions 
are redirected to the appropriate output folder.

Any of the python scripts can be run individually as well - many of them are pipe commands.
Unlike the main.sh and main2.sh the individual scripts can be run from anywhere.

The steps performed are as follows: 

- Generate (annotated) amino acid and nucleotide fasta files
- Generate an annotation file for matching up later, containing organism name, gene name,
  annotation and length of each gene in tab-delimited format
- Run BLAST all vs. all

- Generate a SQLITE database containing:
   rawdata: Concatenated list of all of the raw SEED data
   organisms: A list of organisms and associated SEED features
   processed: A view containing Organism name, gene name, gene length, and annotation.
   blastresults: The blast results [concatenated], in -m9 format (ready for input into MCL)
   neighborhoods: Gene neighborhoods of each gene - neighorhood calculation allows things on either strand
      to be considered a neighbor and looks at number of genes, not genetic distance.

-------------------------------
-------------------------------

DESCRIPTION OF PIPELINE - PART 2 ("main2.sh")

The main2.sh script is the clustering script. Before running it you should define the groups of organisms
you want to cluster (e.g. only clusters in a certain clade, only complete genomes, ...). You will need the
names of all organisms that you want to cluster and call the following function to create a group containing
those organisms:

./addGroupByMatch.py [NAME] [match1] [match2] ...

This script will search the list of organisms for organism names that match [match1], [match2], etc... and
autoamtically add them to a group with name [NAME]. 

A group is automatically created called "all" that contains every organism for which you have data.

To run: ONLY AFTER running main1.sh and setting up all groups for which you want to do clustering, 
call the following function:

./main2.sh [Inflation] [Measurement_technique] [Cutoff]

For each line of the "groups" file:
- Use the database to generate a list of blast hits for only the organisms 
- Call MCL to generate clusters
- Generate raw and flattened results files. Give each cluster run an identifier that explains what parameters
  were passed into it (parameters include inflation, measurement technique, and cutoff)
- Concatinate all of the flattened results files (with unique identifiers) and import them into the
  database as the "clusters" table. Also makes a couple other tables for convenience, including 
  "clusterorgs" which lists the organisms in each cluster.

-------------------------------
-------------------------------

DESCRIPTION OF PIPELINE - PART 3 ("main3.sh")

To run: ONLY after running main1.sh:

./main3.sh

For each file in the "genbank" folder:
- Parse the genbank file to get the whole-genome nucleotide sequence (which must be present)
- Create a table linking organism ID to its genome
- Import the genomes into the database

Genbank filenames must contain the organism ID for the
organism in the file (since there isn't a consistent place to look for them
within the file itself). This step is not necessary to run clustering but is
necessary to run TBLASTN or analyze intergeneic regions.

#########################
# SQL building scripts
#########################

For reference, the SQL code used to build the local sqlite database
with information from other analysis functions is located in 
builddb_1.sql (blast, neighborhoods, and raw data), builddb_2.sql (clustering), 
and builddb_3.sql (genome contigs)

See "help_texts" for detailed descriptions of every python file and shell script
in the src/ folder of this distribution.

-------------------------------
-------------------------------

DESCRIPTION OF PIPELINE - PART 4 ("main4.sh")

To run: ONLY after running main.sh:

./main4.sh [NCORES]

If you don't have a copy of the NCBI CDD database, it automatically downloads and
extracts one in the cd_db folder.

Then it calls RPSBLAST (one core per organism) for all organisms against all of the
gene family profiles in the NCBI CDD database and dumps all of the results to the
SQLite database when it is done. The RPSBLAST results are saved in the
rpsblast_res/ directory.

-------------------------------
-------------------------------

HOW TO REMOVE AN ORGANISM ("removeOrganism.sh")

WARNING: If you specify that you want to remove an organism you cannot get the data back.
Make sure you back up anything you don't want to lose.

Organisms are removed based on the organism ID in their file name (this is why
we have to be so rigorous in our file name definitions). If you just run
removeOrganism.sh like this, it will tell you everything that would be removed
but will NOT remove anything.

./removeOrganism.sh [organism_id]

AFTER looking at the list and deciding everything there is something that can be deleted,
you can permanently delete those files using

./removeOrganism.sh [organism_id] TRUE

After running this script you will have to re-run main.sh, main2.sh, etc...
in order to re-load the database from all the intermediate files. However, this won't take
long becuase only the BLAST results, clusters, etc. that contained the organism that was
deleted are removed, so not much has to be re-run.

