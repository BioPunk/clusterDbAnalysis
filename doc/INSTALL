### INSTALLATION INSTRUCTIONS ###

This package is only available for linux\unix (it might work for mac too but I haven't tested it).

Make sure all the .py and .sh files in the src/ directory are executable:
$ chmod u+x src/*.py
$ chmod u+x src/*.sh

You may also want to do this with all the scritps in the "scripts/" directory
$ chmod u+x scripts/*.py
$ chmod u+x scripts/*.sh

Add the following line to your .bashrc file (emacs -nw ~/.bashrc):
$ source ${ROOTDIR}/SourceMe.sh

where ${ROOTDIR| is the location of the folder into which you cloned the git repository. 
You will then need to save the file and source it (only need to source it once - if you 
log out and back in the .bashrc file is run automatically):

$ source ~/.bashrc

The SourceMe.sh file adds executable scripts do the system PATH and Python libraries
to the PYTHONPATH.

-----------------------------------
-----------------------------------

### DEPENDENCIES ###

The packages have a variety of dependencies depending on how you want to run them.

~~~~
MOST IMPORTANT \ required for large parts of the package
~~~~

NCBI BLAST: BlastP is used as a basis for generating gene clusters. BLASTN and TBLASTN are also 
        used in various scripts. RPSBLAST is included with the package and is used for comparison to the
	CDD database. This toolkit uses the newer version of BLAST (BLAST+), not Blastall

MCL: Default clustering tool used to generate gene clusters.

Sqlite3: Used to store and query blast, cluster and alignment\tree data. IMPORTANT: Make sure you have the latest version!
         Older versions of SQLite suffer bugs when making indexes that are too large in older versions and index creation will fail as a result
	 (making lookups very slow)

Python (I used 2.6, should also work for 2.7): Most of the code is written for python. The rest is written for BASH 
       	       	           	       	     which is included in most Linux distributions.

~Required Python packages~

BioPython: Used for reading and writing various alignment formats and genome visualization.

ETE- Used for tree visualization and manipulation.

Numpy: Used for assorted calcualtions and data organization. Also makes biopython run much more smoothly and you probably should have it anyway since
       tons of stuff depends on it.

Ruffus: Python parallelization package. Used to parallelize BLAST and BLASTN functions (the
        parallelization option built into NCBI BLAST doesn't work on all machines and isn't as
	easy to split into pairwise organism comparisons).

~~~~
ALSO USEFUL \ required for small parts of the package
~~~~

FastTree (http://www.microbesonline.org/fasttree/) - Fast treeing program, at the expense of some accuracy. Required to make trees with FastTree

MaFFT - Fast and (fairly) accurate multiple-alignment software used in alignment wrappers in this toolkit.

Matplotlib: Used for assorted calculations (sparsely used)

MyRast: Contains some useful scripts for alignment and tree manipulation (In ITEP, we only require it if you want to download RAST data from the command line - you can also
	download the files from the RAST website and not install MyRast).
	Requires Perl 5 and various perl packages (install with aptitude or CPAN if it complains).

PyQt4 - Used for certain tree visualization scripts, required to interactively display trees with ETE

RaxML - Accurate but slow treeing program.

ReportLab - Needed for Biopython graphics (e.g. neighborhood trees).

Scipy - Currently only used for hierarchical clustering while drawing heatmaps. If you don't want to use PlotHeatmaps.py you don't need this.

ORTHOMCL-SPECIFIC REQUIREMENTS:

If you want to run OrthoMCL you need to install it and its dependencies, which include:
    - MySQL
    - Perl 5
    - DBI and DBD::mysql , both of which can be installed (as root) by using CPAN if you don't have them

$ sudo cpan DBI
$ sudo cpan DBD::mysql

See the orthoMCL help for more details.

WARNING: the orthoMCL requires you to set the global variable local_infile to TRUE
	 or else mysql will refuse to load your BLAST file
	 (it will tell you "the used command is not allowed").

You can set that by executing the command (as the mySQL root)
SET GLOBAL local_infile=TRUE;
or else include a command to set that variable in the DBI string like in example orthoMCL config file.

-----------------------------------
-----------------------------------

### DATA SETUP ###

To actually run the programs you need some data. I'll consider the directory created when
you check this out of git the "root" ${ROOTDIR} directory.

There are several convenient ways to import data into ITEP.

METHOD 1: RAST

If you upload your newly-sequenced genome to RAST (rast.nmpdr.org) you can download the
two required input files directly from there. The two files you need are:

Spreadsheet (tab-delimited) : Place this file in the ${ROOTDIR}/raw/ directory with the
same name as given to it by default by RAST.
Genbank : Place this file in the ${ROOTDIR}/genbank/ directory with the same name
as given to it by default by RAST.

METHOD 2: USER-SUPPLIED GENBANK FILE

If the user has a genbank file from any source including METHOD 3 or METHOD 4 below (or from RAST), 
here is how to import it into ITEP:

a) Put the genbank file in the root directory (or some placeholder directory, but NOT genbank/ or
raw/)

b) Call convertGenbank2table.py

The script automatically generates a raw file for you and places it in the right place, giving it
gene IDs in the format expected by ITEP. It also copies the genbank file into the location expected
by ITEP, and adds any locus tags, gene names, or protein IDs to the aliases table so that they become
searchable in the database.

This script might not work depending on what data is in your genbank file. Please email me or file
bug reports if you have issues with yours. It has been tested on Genbank files from the RefSeq
database, RAST, and those generated from the KBase genome objects (see methods 3 and 4 below).

METHOD 3: NCBI GENBANK FILES

(beta) We have a sometimes-problematic script to download genbank files from NCBI based on
taxIDs or accession numbers. Watch the output carefully, but if it works you'll have genbank files
in the right format to import into ITEP using the scripts from METHOD 2 above. Otherwise, go to the
FTP site and download all the genbank files for your organism of interest, concatinate them (with the
cat command) and then follow the directions in METHOD 2.

METHOD 4: DOE KBASE

The kbaseGenomeToGenbank.py function (located in scripts/) will take a DOE KBase genome object
(the output of annotate_genome) and output a genbank file with appropriate format for input to ITEP.

Once you have the genbank file, follow the procedure in METHOD 2 to set up the Genbank file for 
import into ITEP.


-----------------------------------
-----------------------------------

FILE FORMAT STANDARDS

The following files are generated by the interface scripts. This documention is intended for developers.

### 1: Genbank files (required) ###
# 
# You need a genbank file for every organism. The following information is taken from the genbank files at a minimum:
# - Organism (in the /organism="[organism name]" line )
# - Tax ID (in a /db_xref="Taxon:[taxid]" line )
#
# These should be present in all the genbank files from Genbank (ftp.ncbi.nih.gov/genomes/Bacteria). It is assumed that
# any duplicates of such lines are all identical.
#
# Additional requirements: 
# 1: You need ONE genbank file per organism. Concatinate the genbank files for all the contigs (after generating a raw file, if you need one)
# 2: The contig ID must not have any spaces in it.
#
### 2: raw files ###
#
# Raw files are tab-delimited files containing information needed for our analysis.
# They must be placed in the ${ROOTDIR}/raw folder.
#
# The columns of a raw file are as follows:
#
# contig_id       feature_id      type    location        start   stop    strand  function        aliases figfam  evidence_codes  nucleotide_sequence     aa_sequence
#
# The feature_id for any protein-encoding gene must have the format:
# fig|#.#.peg.# (e.g. fig|83333.1.peg.1)
#
# - The first two numbers (83333.1) must match the organism ID for the organism containing that gene.
# - The overall feature ID must be unique for each gene.
#
# Type should be "peg" for all proteins. Anything that is not a protein is ignored.
#
# Start/stop is the start/stop of the actual gene on the specified contig (start > stop for - strand genes).
# 
# - The start\stop are 1-indexed from the beginning of the contig on which the feature is found.
#
# Strand is + or -
#
# Function is the functional annotation.
#
# nucleotide_sequence is the nucleotide sequence encoding for the protein and aa_sequence is the translated amino acid sequence.
#
# All other fields (location, aliases, figfam, evidence_codes, ...) are ignored.
#
#
### 3: organism file ###
#
# This is automatically generated from the genbank files, except for abbreviations which must be edited manually
# if you need them (the default is to just use DEFAULT_## where ## is an incremental number).
#
# The file is always in ${ROOTDIR} and has three columns: Organism name, abbreviation, and ID.
#
# Methanosarcina acetivorans C2A  aceC2A  188937.1
# Methanosarcina mazei GO1        mazGO1  192952.1
#
### 4: groups file ###
#
# This file comes automatically-generated with a default group containing all the organisms. You should
# add or remove additional groups according to the analyses you want to perform.
#
# This file allows you to specify multiple groups of organisms that you want to cluster with the same set of
# parameters. In it, the first column is a (unique but arbitrary) name of the organism group, and the second one
# contains a semicolon-delimited list of all of the strains you are analyzing. For example:
#
# Methanosarcina	Methanosarcina acetivorans C2A;Methanosarcina barkeri Fusaro; Methanosarcina mazei GO1
# mazei			Methanosarcina mazei Go1
#
# Use the addGroupByMatch.sh function to add groups to the groups file based on searches through the organism file,
# or make the lists manually. The run IDs will use the group names as their base (along with user-defined clustering parameters).
#